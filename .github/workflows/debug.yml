name: Debug Workflow

on:
  # Manual trigger with configurable options
  workflow_dispatch:
    inputs:
      branch:
        description: 'Branch to debug'
        required: true
        default: 'develop'
      verbose_logging:
        description: 'Enable verbose logging'
        type: boolean
        default: true
      test_scope:
        description: 'Test scope'
        type: choice
        options:
          - full
          - backend
          - frontend
          - database
          - api
        default: 'full'
  
  # Automatic triggers
  pull_request:
    types: [opened, synchronize, reopened]
    branches: [main, develop]
    paths:
      - 'backend/**'
      - 'components/**'
      - 'hooks/**'
      - 'lib/**'
      - 'app/**'
      - 'package.json'
      - 'backend/package.json'
  
  push:
    branches: [main, develop, feature/**, bugfix/**]
    paths:
      - 'backend/**'
      - 'components/**'
      - 'hooks/**'
      - 'lib/**'
      - 'app/**'
      - 'package.json'
      - 'backend/package.json'
  
  # Scheduled runs for regular testing
  schedule:
    - cron: '0 0 * * 1' # Weekly on Monday at midnight UTC

jobs:
  determine_config:
    name: Determine Configuration
    runs-on: ubuntu-latest
    outputs:
      branch: ${{ steps.set-branch.outputs.branch }}
      verbose: ${{ steps.set-config.outputs.verbose }}
      test_scope: ${{ steps.set-config.outputs.test_scope }}
    
    steps:
      - name: Set branch
        id: set-branch
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "branch=${{ github.event.inputs.branch }}" >> $GITHUB_OUTPUT
          else
            echo "branch=${{ github.ref_name }}" >> $GITHUB_OUTPUT
          fi
      
      - name: Set configuration
        id: set-config
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "verbose=${{ github.event.inputs.verbose_logging }}" >> $GITHUB_OUTPUT
            echo "test_scope=${{ github.event.inputs.test_scope }}" >> $GITHUB_OUTPUT
          else
            echo "verbose=true" >> $GITHUB_OUTPUT
            echo "test_scope=full" >> $GITHUB_OUTPUT
          fi

  debug_test:
    name: Debug Tests
    needs: determine_config
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: timescale/timescaledb:latest-pg14
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          ref: ${{ needs.determine_config.outputs.branch }}
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          cd backend && npm ci
      
      - name: Setup debug environment
        run: |
          mkdir -p logs screenshots test-reports
          echo "DEBUG=true" >> $GITHUB_ENV
          if [ "${{ needs.determine_config.outputs.verbose }}" == "true" ]; then
            echo "VERBOSE_LOGGING=true" >> $GITHUB_ENV
            echo "DEBUG_LEVEL=verbose" >> $GITHUB_ENV
          fi
      
      # Run backend tests with enhanced reporting
      - name: Run backend tests
        if: ${{ needs.determine_config.outputs.test_scope == 'full' || needs.determine_config.outputs.test_scope == 'backend' }}
        run: |
          cd backend
          npm test -- --reporter=junit --outputFile=test-results.xml --verbose
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_USER: test
          DB_PASSWORD: test
          DB_NAME: test_db
          REDIS_URL: redis://localhost:6379
          DEBUG: ${{ env.DEBUG }}
          VERBOSE_LOGGING: ${{ env.VERBOSE_LOGGING }}
      
      # Generate HTML test report
      - name: Generate test report
        uses: dorny/test-reporter@v1
        if: always() && (needs.determine_config.outputs.test_scope == 'full' || needs.determine_config.outputs.test_scope == 'backend')
        with:
          name: Backend Tests
          path: backend/test-results.xml
          reporter: jest-junit
      
      # Run database validation tests
      - name: Setup and run database tests
        if: ${{ needs.determine_config.outputs.test_scope == 'full' || needs.determine_config.outputs.test_scope == 'database' }}
        run: |
          # Create test scripts directory
          mkdir -p backend/src/scripts backend/src/tests
          
          # Download test scripts from repository
          curl -s -o backend/src/scripts/setup-test-db.js https://raw.githubusercontent.com/${{ github.repository }}/main/scripts/db-test-scripts/setup-test-db.js || echo '
          // Setup test database with mock data
          const { Pool } = require("pg");
          
          const pool = new Pool({
            host: process.env.DB_HOST || "localhost",
            port: process.env.DB_PORT || 5432,
            user: process.env.DB_USER || "test",
            password: process.env.DB_PASSWORD || "test",
            database: process.env.DB_NAME || "test_db"
          });
          
          async function setupTestDb() {
            console.log("Setting up test database...");
            
            try {
              // Create tables if they don't exist
              await pool.query(`
                CREATE TABLE IF NOT EXISTS campaigns (
                  id SERIAL PRIMARY KEY,
                  name VARCHAR(255) NOT NULL,
                  status VARCHAR(50) NOT NULL,
                  created_at TIMESTAMP DEFAULT NOW(),
                  updated_at TIMESTAMP DEFAULT NOW()
                );
                
                CREATE TABLE IF NOT EXISTS metrics (
                  id SERIAL PRIMARY KEY,
                  campaign_id INTEGER REFERENCES campaigns(id),
                  name VARCHAR(255) NOT NULL,
                  value NUMERIC NOT NULL,
                  date TIMESTAMP NOT NULL,
                  created_at TIMESTAMP DEFAULT NOW()
                );
              `);
              
              // Insert test data
              await pool.query(`
                INSERT INTO campaigns (name, status)
                VALUES 
                  ('Test Campaign 1', 'active'),
                  ('Test Campaign 2', 'draft'),
                  ('Test Campaign 3', 'completed')
                ON CONFLICT DO NOTHING;
              `);
              
              console.log("Test database setup complete");
            } catch (error) {
              console.error("Error setting up test database:", error);
              process.exit(1);
            } finally {
              await pool.end();
            }
          }
          
          setupTestDb();
          ' > backend/src/scripts/setup-test-db.js
          
          # Create test files if they don't exist
          curl -s -o backend/src/tests/db-schema.test.js https://raw.githubusercontent.com/${{ github.repository }}/main/scripts/db-test-scripts/db-schema.test.js || echo '
          // Database schema validation tests
          const { Pool } = require("pg");
          
          const pool = new Pool({
            host: process.env.DB_HOST || "localhost",
            port: process.env.DB_PORT || 5432,
            user: process.env.DB_USER || "test",
            password: process.env.DB_PASSWORD || "test",
            database: process.env.DB_NAME || "test_db"
          });
          
          describe("Database Schema Tests", () => {
            afterAll(async () => {
              await pool.end();
            });
            
            test("campaigns table has expected columns", async () => {
              const result = await pool.query(`
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_name = 'campaigns'
              `);
              
              const columns = result.rows.reduce((acc, row) => {
                acc[row.column_name] = row.data_type;
                return acc;
              }, {});
              
              expect(columns).toHaveProperty("id");
              expect(columns).toHaveProperty("name");
              expect(columns).toHaveProperty("status");
            });
          });
          ' > backend/src/tests/db-schema.test.js
          
          # Add scripts to package.json
          cd backend
          if ! grep -q "test:db-schema" package.json; then
            node -e '
              const fs = require("fs");
              const pkg = JSON.parse(fs.readFileSync("package.json"));
              if (!pkg.scripts) pkg.scripts = {};
              pkg.scripts["test:db-schema"] = "jest src/tests/db-schema.test.js";
              pkg.scripts["test:data-integrity"] = "jest src/tests/data-integrity.test.js";
              fs.writeFileSync("package.json", JSON.stringify(pkg, null, 2));
            '
          fi
          
          # Run the database tests
          node src/scripts/setup-test-db.js
          npm run test:db-schema
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_USER: test
          DB_PASSWORD: test
          DB_NAME: test_db
      
      # Run API tests
      - name: Run API tests
        if: ${{ needs.determine_config.outputs.test_scope == 'full' || needs.determine_config.outputs.test_scope == 'api' }}
        run: |
          cd backend
          # Create API test file if it doesn't exist
          mkdir -p src/tests
          if [ ! -f src/tests/api.test.js ]; then
            cat > src/tests/api.test.js << 'EOF'
            const request = require('supertest');
            const app = require('../app');
            
            describe('API Endpoints', () => {
              test('GET /api/overview returns 200', async () => {
                const response = await request(app).get('/api/overview');
                expect(response.statusCode).toBe(200);
              });
              
              test('GET /api/campaigns returns 200', async () => {
                const response = await request(app).get('/api/campaigns');
                expect(response.statusCode).toBe(200);
              });
            });
            EOF
          fi
          
          # Install supertest if not already installed
          npm install --save-dev supertest
          
          # Run the API tests
          npx jest src/tests/api.test.js --forceExit
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_USER: test
          DB_PASSWORD: test
          DB_NAME: test_db
          REDIS_URL: redis://localhost:6379
          NODE_ENV: test
      
      # Browser testing
      - name: Setup Chrome
        uses: browser-actions/setup-chrome@latest
        if: ${{ needs.determine_config.outputs.test_scope == 'full' || needs.determine_config.outputs.test_scope == 'frontend' }}
      
      - name: Setup and run browser tests
        if: ${{ needs.determine_config.outputs.test_scope == 'full' || needs.determine_config.outputs.test_scope == 'frontend' }}
        run: |
          # Create browser test script
          mkdir -p scripts
          curl -s -o scripts/ci-browser-tests.js https://raw.githubusercontent.com/${{ github.repository }}/main/scripts/ci-browser-tests.js || cp scripts/browser-action-demo.js scripts/ci-browser-tests.js
          
          # Install puppeteer
          npm install --save-dev puppeteer
          
          # Start the application in the background
          npm run dev &
          sleep 10
          
          # Run the browser tests
          node scripts/ci-browser-tests.js
          
          # Capture the exit code
          EXIT_CODE=$?
          
          # Kill the background process
          kill $(jobs -p) || true
          
          # Exit with the captured exit code
          exit $EXIT_CODE
      
      # Performance testing
      - name: Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v9
        if: ${{ needs.determine_config.outputs.test_scope == 'full' || needs.determine_config.outputs.test_scope == 'frontend' }}
        with:
          urls: |
            http://localhost:3000/
          temporaryPublicStorage: true
      
      # Upload all artifacts
      - name: Upload test artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results
          path: |
            backend/test-results.xml
            test-reports/
            screenshots/
            .lighthouseci/
          retention-days: 14
      
      # Notify on completion
      - name: Notify on success
        if: success()
        run: |
          echo "Debug workflow completed successfully!"
          echo "Test scope: ${{ needs.determine_config.outputs.test_scope }}"
          echo "Branch: ${{ needs.determine_config.outputs.branch }}"
      
      - name: Notify on failure
        if: failure()
        run: |
          echo "Debug workflow failed!"
          echo "Test scope: ${{ needs.determine_config.outputs.test_scope }}"
          echo "Branch: ${{ needs.determine_config.outputs.branch }}"
